<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>STAT 227: Statistical Design and Analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Anthony Scotina" />
    <script src="libs/header-attrs-2.6/header-attrs.js"></script>
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STAT 227: Statistical Design and Analysis
## Chi-Square Tests
### Anthony Scotina

---






&lt;!--
pagedown::chrome_print("~/Dropbox/Teaching/03-Simmons Courses/MATH227-Intermediate Statistics/Lecture Slides/06-Chi_Square_Tests/06-Chi_Square_Tests.html")
--&gt;

# Introduction

So far, we have performed **comparative analyses** that looked at a single *mean* or *proportion* (or some other statistic), or compared means or proportions **between two groups**. 

- proportion of "no opinion on offshore drilling" among college graduates vs. non-college graduates

- average IMDB.com rating between action and romance movies

- average income (or **median** income) between Cleveland, OH and Sacramento, CA

--

Regardless the setting, we want to make explicit the relationship between:

- an **outcome/response** variable *y*, also called the **dependent variable**, and

- an **explanatory** variable *x*, also called an **independent variable** or **covariate**

---

# Multiple Categories

What if we had the following:

.pull-left[
**Outcome/Response** (*y*)

- Do you think funding for space exploration is too little, about right, or too much? (*three levels*; *categorical*)
]

.pull-right[
**Explanatory** (*x*)

- Political party: Dem, Ind, Rep (*three levels*; *categorical*)
]

We cannot calculate a *difference between two proportions* here.  There are more than two groups!

- Luckily, we can perform a chi-square (&amp;chi;&lt;sup&gt;2&lt;/sup&gt;) test. 

---

# Needed Packages


```r
library(mosaic)
library(infer)
library(tidyverse)
```

---

class: center, middle, frame

# Goodness-of-Fit Tests

---

# Zodiac Signs

Does your zodiac sign predict how successful you will be?

The `Zodiac.csv` dataset (downloadable from the online campus) contains data from a study conducted by *Fortune* magazine. 

- Data consist of zodiac signs of 256 heads of the largest 400 companies




```r
Zodiac
```

```
## # A tibble: 256 x 1
##    Sign  
##    &lt;chr&gt; 
##  1 Pisces
##  2 Pisces
##  3 Pisces
##  4 Pisces
##  5 Pisces
##  6 Pisces
##  7 Pisces
##  8 Pisces
##  9 Pisces
## 10 Pisces
## # … with 246 more rows
```

---

# Zodiac Signs (EDA)


```r
Zodiac_tab = tally( ~ Sign, data = Zodiac)
Zodiac_tab
```

```
Sign
   Aquarius       Aries      Cancer   Capricorn      Gemini         Leo 
         24          23          23          22          18          20 
      Libra      Pisces Saggitarius     Scorpio      Taurus       Virgo 
         18          29          19          21          20          19 
```


```r
gf_bar( ~ Sign, data = Zodiac, fill = "steelblue") + 
  coord_flip()
```

--


```r
pie(Zodiac_tab) #LOL JK
```

---

# Zodiac Signs

**What do we notice?**

- There appears to be *some* variation in the number of births per sign (e.g., more *Pisces* than other signs). 

- Are the discrepancies in *counts* enough to claim that *successful* people are more likely to be born under some signs than others?

--

*Let's think about this another way.*

- If the 256 births were distributed **uniformly** across the 12 zodiac signs, how many would we *expect* to occur under each sign?

- `\(256/12=21.3\)` per sign
    - How closely do the **observed** numbers of births per sign fit the **expected** numbers (i.e., the "null model")?

---

# Goodness-of-Fit Tests

In a **Goodness-of-Fit Test**, we are seeing how "good" (or, how *well*) a null model fits the **observed data**. 

- In the zodiac example, the null model consists of births that are *uniformly distributed over the 12 signs*. 


While this is technically a **hypothesis test**, there is no single parameter to estimate (such as the *proportion* of Scorpio). 

- Rather, there are 12 hypothesized proportions (or *counts*) to consider together. 

- `\(H_{0}\)`: Births are *uniformly distributed* over zodiac signs. 

- `\(H_{a}\)`: Births are *not uniformly distributed* over zodiac signs. 

---

# Assumptions for Goodness-of-Fit Tests

Typically these data are organized in summary tables of *counts*, rather than having an osbervation for each individual. 

1. **Categorical Data Condition**: The data must be categorical. 
    - Usually straightforward to check.

2. **Independence Assumption**: The counts of the categories of the categorical variable should be *independent* of each other. 
    - The birthdates of the 256 company heads are (probably) randomly distributed throughout the year. 

3. **Sample Size Assumption**: There should be *at least 5 expected individuals* in each category. 
    - "Expected" referring to what we would *expect* to see under the **null hypothesis**. 

---

# Chi-Square Statistic

The **chi-square statistic** is a *test statistic* for categorical variables: `$$\chi^{2}=\sum_{i=1}^{k}\frac{(O_{i}-E_{i})^{2}}{E_{i}}$$`

where `\(O_{i}\)` is the *observed* value in cell *i*, `\(E_{i}\)` is the *expected* value in cell *i*, and *k* is the total number of cells. 

--

Under `\(H_{0}\)`, the test statistic follows a **chi-square** distribution. 

- In other words, the **chi-square** distribution is the **null distribution** for a goodness-of-fit test. 

- The distribution is right-skewed, and it is *always positive*. (i.e., `\(\chi^{2}&gt;0\)`)

---

# Chi-Square Distribution

.center[
&lt;img src="chisquare_dist.png" width="75%" /&gt;
]

---

# Degrees of Freedom

The *shape* of the distribution depends on the number of **degrees of freedom** (*df*). 

- Assuming the null hypothesis is true (always a first step in hypothesis testing), `$$df=\text{number of categories}-1$$`
 

For the zodiac example, `$$df=12-1 = 11$$`

---

# Chi-Square Statistic and p-value

In the zodiac example, `$$\chi^{2}=\sum_{i=1}^{k}\frac{(O_{i}-E_{i})^{2}}{E_{i}}=\frac{(29-21.3)^2}{21.3}+\cdots+\frac{(18-21.3)^2}{21.3}=5.09$$`

--

Recall: 

&gt; **p-value**: The probability of obtaining a test statistic just as extreme or more extreme than the observed test statistic *assuming the null hypothesis (H&lt;sub&gt;0&lt;/sub&gt;) is true*

In a **goodness-of-fit test**:

- The **p-value** corresponds to the area under the `\(\chi^{2}\)` curve with `\(df=11\)` *greater than our observed test statistic* (5.09). 

---

# The p-value

&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-9-1.png" width="50%" /&gt;


```r
pchisq(5.09, df = 11, lower.tail = FALSE)
```

```
## [1] 0.9267297
```

---

# The p-value

The p-value for this hypothesis test is **0.927**. 

This means that, *if the zodiac signs of executives were in fact distributed uniformly*, an observed chi-square value of **5.09 or higher** would occur about 93% of the time.

- This is not unusual at all!

**Conclusion**

We *fail to reject the null hypothesis*, and conclude that these data show virtually *no evidence of non-uniform distribution* of zodiac signs among executives. 

---

# The Role of df in p-value

Unlike *Normal* and *t* distributions (from theory-based hypothesis tests, for example), the `\(\chi^{2}\)` distribution is **skewed**. 

- As the *number of categories* (and hence, the *df*) increases, the degree of skewness in the `\(\chi^{2}\)` distribution changes. 

While `\(\chi^{2}=5.09\)` is *not extreme* in the distribution with `\(df=11\)`, it might appear much *more extreme* in a distribution with smaller *df*, or *less extreme* with even higher *df*. 

---

# The p-value of 5.09 when df = 3

&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-11-1.png" width="50%" /&gt;

---

# The p-value of 5.09 when df = 30

&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-12-1.png" width="50%" /&gt;

---



# Dog Data!!!

Is **bite frequency** *distributed uniformly* among dog breeds in New York City?

Run the following code to install the `nycdogs` R package:


```r
devtools::install_github("kjhealy/nycdogs")
```

**OR** download the `nyc_bites.csv` and `nyc_license.csv` datasets from Moodle. 

---

# `nyc_bites` data




```r
View(nyc_bites)
```


```r
bite_tab = nyc_bites %&gt;%
  count(breed, sort = TRUE) %&gt;%
  slice(1:8) # Extract only the TOP 8!
bite_tab
```

```
## # A tibble: 8 x 2
##   breed                                    n
##   &lt;chr&gt;                                &lt;int&gt;
## 1 Pit Bull                              1924
## 2 Shih Tzu                               359
## 3 American Pit Bull Mix - Pit Bull Mix   347
## 4 American Pit Bull Terrier-Pit Bull     343
## 5 Chihuahua                              341
## 6 German Shepherd                        276
## 7 Mixed-Other                            267
## 8 Yorkshire Terrier                      230
```

---

# Goodness-of-Fit Test

Let's use only the species with bite counts over 200:


```r
nyc_bites_200 = nyc_bites %&gt;%
  filter(breed %in% bite_tab$breed)
```

`\(H_{0}\)`: Bite count is *unformly distributed* across dog breed. 

`\(H_{a}\)`: Bite count is *not unformly distributed* across dog breed. 

Perform the **chi-square goodness-of-fit test**!

---

# Solution

Under `\(H_{0}\)`, the test statistic follows a `\(\chi^{2}\)` distribution with `\(df = 8-1=7\)`. 


```r
chisq.test(
  tally( ~ breed, data = nyc_bites_200)
)
```

```
## 
## 	Chi-squared test for given probabilities
## 
## data:  tally(~breed, data = nyc_bites_200)
## X-squared = 4497, df = 7, p-value &lt; 2.2e-16
```

With `\(\chi^{2}=4497\)` (!!!) and p-value &lt; 0.05, we reject `\(H_{0}\)` and conclude that bite count is *not unformly distributed* across dog breed. 

---

# Just checking...

The observed `\(\chi^{2}=4497\)` was **huge**! What do you think was the reason why?

--

.center[
&lt;img src="pitbull.jpg" width="209" /&gt;
]

---

class: center, middle, frame

# (Theory-Based) Chi-Square Test for Independence

---

# Chi-Square Test for Independence

What we have done so far with the **goodness of fit test** is look at a *single categorical variable* with multiple levels. 

The statistics behind a &amp;chi;&lt;sup&gt;2&lt;/sup&gt; test easily extend to *multiple* categorical variables.
- This is called a &amp;chi;&lt;sup&gt;2&lt;/sup&gt; **test for independence**.

.pull-left[
**Outcome/Response** (*y*)

- Do you think funding for space exploration is too little, about right, or too much? (*three levels*; *categorical*)
]

.pull-right[
**Explanatory** (*x*)

- Political party: Dem, Ind, Rep (*three levels*; *categorical*)
]

---

# GSS Data

Download/Import the `gss.csv` dataset, which contains data on 149 GSS respondents. 

The [General Social Survey](http://gss.norc.org/) (GSS) is a sociological survey that keeps records of the concerns, experiences, attitudes, and practices of residents of the United States. 




```r
View(gss)
```

---

# Exploratory Data Analysis

We are interested in the relationship between **political party** and **opinions on space funding**.
- Data are located in the `party` and `NASA` variables.


```r
select(gss, party, NASA)
```

```
# A tibble: 149 x 2
   party NASA       
   &lt;chr&gt; &lt;chr&gt;      
 1 Ind   TOO LITTLE 
 2 Ind   ABOUT RIGHT
 3 Dem   ABOUT RIGHT
 4 Ind   TOO LITTLE 
 5 Ind   TOO MUCH   
 6 Ind   TOO LITTLE 
 7 Ind   ABOUT RIGHT
 8 Dem   ABOUT RIGHT
 9 Dem   TOO LITTLE 
10 Ind   TOO LITTLE 
# … with 139 more rows
```

---

# Exploratory Data Analysis

First, let's generate a **contingency table** of responses for each variable. 


```r
gss_table = tally(NASA ~ party, data = gss)
gss_table
```

```
             party
NASA          Dem Ind Rep
  ABOUT RIGHT  22  37  17
  TOO LITTLE    8  13   9
  TOO MUCH     13  22   8
```

Are **political party** and **opinions on space funding** *independent*?

--

If they were, we would expect (for example): `$$P(\text{Too much funding})=P(\text{Too much funding} | \text{Democrat})$$`

- In other words, the probability of **any person** believing we spend *too much* on space funding is equal to the probability of a **Democrat** believing we spend *too much* on space funding. 

---

# Exploratory Data Analysis

It might be easier to detect any trends by constructing a **barplot**:


```r
gf_bar( ~ party, fill = ~ NASA, data = gss) + 
  labs(fill = "NASA Funding")
```

&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-25-1.png" width="50%" /&gt;

---

# Exploratory Data Analysis


```r
gf_bar( ~ party, fill = ~ NASA, data = gss, 
        position = "fill") + 
  labs(fill = "NASA Funding")
```

&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-26-1.png" width="50%" /&gt;

---

# Exploratory Data Analysis

It doesn't look like there are major differences in how Democrats, Independents, and Republicans support space exploration. 

- But let's investigate this further using a **chi-square test for independence**!

--

`\(H_{0}\)`: There is **no relationship** between political party and attitude towards space exploration (i.e., these variables are **independent**). 

`\(H_{a}\)`: There is **a relationship** between political party and attitude towards space exploration.

---

# Assumptions and Conditions

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Dem &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Ind &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Rep &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ABOUT RIGHT &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 17 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; TOO LITTLE &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; TOO MUCH &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

In order to perform a **chi-square test for independence**, we assume:

--

1. The variables are **categorical**. 

2. Observations are **independent** (i.e., each individual is independent of one another and does not influence another's views).

3. An individual does not belong to multiple levels of the same variable (e.g., no one is both a Democrat and Republican). 

4. Each **expected cell count** is at least 5. 
    - Only important for the *theory-based* test...

---

# Expected Counts

For the **goodness of fit test**, expected counts were calculated using the assumption that each level of a single category was *equally likely* (i.e., the null hypothesis). 

For a **test for independence**, expected counts are calculated using the assumption that each level **within each category** is *equally likely*. 

- For example, the proportion of *Democrats* who think funding for space exploration is **too little** is the same as the proportion of *Democrats* who think funding for space exploration is **about right** or **too much**. 

In a test for independence, **expected counts** are calculated using the following: For each cell, `$$E=\frac{(\text{Row total})(\text{Column total})}{\text{Sample size}}$$`

---

# Expected Counts

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Funding &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Dem &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Ind &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Rep &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Too Little &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; About Right &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 37 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 17 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Too Much &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

--

The **expected counts** are given in parentheses:

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Funding &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Dem &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Ind &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Rep &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Too Little &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (8.7) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (14.5) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (6.8) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; About Right &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 37 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 17 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (21.9) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (36.7) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (17.3) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Too Much &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (12.4) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (20.8) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (9.8) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

---

# Test Statistic and p-value

The **test statistic** for a test for independence might look familiar: `$$\chi^{2}=\sum_{i=1}^{k}\frac{(O_{i}-E_{i})^{2}}{E_{i}}$$`

The only difference is the **degrees of freedom**: `$$df=(\text{number of rows}-1)(\text{number of columns}-1)$$`
- In this example, `\(df=(3-1)(3-1)=4\)`. 

--


```r
chisq.test(gss_table)
```

```

	Pearson's Chi-squared test

data:  gss_table
X-squared = 1.3261, df = 4, p-value = 0.8569
```

- At the 0.05 level of significance, **fail to reject the null**. We cannot conclude that opinion on NASA funding is dependent on political party. 

---

class: center, middle, frame

# (Simulation-Based) Chi-Square Test for Independence

---

# Permutation Chi-Square Tests (with R)

.center[
&lt;img src="infer_hex.png" width="20%" /&gt;

&lt;img src="help_calculate.png" width="80%" /&gt;
]

---

# Reminder: `infer`

.center[
&lt;img src="infer.png" width="494" /&gt;
]

---

# One Permutation

Let's take one permutation from the `gss` data:


```r
one.perm = gss %&gt;%
  specify(response = NASA, explanatory = party) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1, type = "permute")
View(one.perm)
```

---

# One Permutation

Now let's calculate the &amp;chi;&lt;sup&gt;2&lt;/sup&gt; statistic for the *single permutation*:




```r
one.perm %&gt;%
  calculate(stat = "Chisq")
```

```
Response: NASA (factor)
Explanatory: party (factor)
Null Hypothesis: independence
# A tibble: 1 x 1
   stat
  &lt;dbl&gt;
1  5.33
```

--

Remember, this is in a world where the *null is true*. So we should expect the statistic to be relatively small. 

.center[
&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-37-1.png" width="25%" /&gt;
]

---

# Many Permutations

As before, let's generate 1,000 (or more) permutations!




```r
null_distribution_NASA = gss %&gt;%
  specify(response = NASA, explanatory = party) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "Chisq")
```

---

# Visualize the Null Distribution


```r
visualize(null_distribution_NASA) + 
* shade_p_value(obs_stat = 1.33, direction = "greater")
```

&lt;img src="07-Chi_Square_Tests_files/figure-html/unnamed-chunk-40-1.png" width="50%" /&gt;

---

# Side Note: Obtaining the Test Statistic

We obtained the test statistic `\(\chi^{2}=1.33\)` when we used `chisq_test()` earlier. 
- If you want to skip that step and just stick with `infer` pipelines, you can just comment out a couple lines:


```r
chisq_stat = gss %&gt;%
  specify(response = NASA, explanatory = party) %&gt;%
  #hypothesize(null = "independence") %&gt;%
  #generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "Chisq")
chisq_stat
```

```
Response: NASA (factor)
Explanatory: party (factor)
# A tibble: 1 x 1
   stat
  &lt;dbl&gt;
1  1.33
```

This calculates &amp;chi;&lt;sup&gt;2&lt;/sup&gt; for the **original sample**, rather than for each simulated permutation of the sample. 

---

# p-value

We can use `get_p_value()` to get the P-value:


```r
gss %&gt;%
  specify(response = NASA, explanatory = party) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "Chisq") %&gt;%
* get_p_value(obs_stat = 1.33, direction = "greater")
```

```
# A tibble: 1 x 1
  p_value
    &lt;dbl&gt;
1    0.85
```

--

Compare this with the P-value obtained using the **theoretical test**:


```

	Pearson's Chi-squared test

data:  gss_table
X-squared = 1.3261, df = 4, p-value = 0.8569
```



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false,
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
