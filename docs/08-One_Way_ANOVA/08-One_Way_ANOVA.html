<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>STAT 227: Statistical Design and Analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Anthony Scotina" />
    <script src="libs/header-attrs-2.6/header-attrs.js"></script>
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STAT 227: Statistical Design and Analysis
## One-Way ANOVA
### Anthony Scotina

---






&lt;!--
pagedown::chrome_print("~/Dropbox/Teaching/03-Simmons Courses/MATH227-Intermediate Statistics/Lecture Slides/07-One_Way_ANOVA/07-One_Way_ANOVA.html")
--&gt;

class: center, middle, frame

# One-Way ANOVA

---

# Needed Packages


```r
library(tidyverse)
library(mosaic)
library(infer)
```

---

# Motivating Example

It is known that "*danceability*" (and other music-related metrics) are not the same across different *songs* and *genres*. 

- This is related to *many* factors. 

**Two questions:**

1. Are there *significant differences* in danceability **between** genres?

2. Are there *significant differences* in danceability **within** genres?

---

# `spotify_songs` data 

We'll use a smaller version of the `spotify_songs` data from [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md)

- This dataset contains song statistics for over 30,000 songs scraped from Spotify. 

We'll select 250 songs at random:


```r
set.seed(227) # RUN THIS!!!
spotify_songs = read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv')
spotify_songs = spotify_songs %&gt;%
  slice_sample(n = 250) 
```

**The set-up**:

1. Danceability (`danceability`) is the **outcome variable** (*y*). 

2. Genre (`playlist_genre`) is the **explanatory variable** (*x*). 

    - Note that `playlist_genre` is *categorical* with more than two levels. 
  
---

# Exploratory Data Analysis


```r
favstats( ~ danceability, data = spotify_songs) %&gt;%
  select(median, mean, sd, n)
```

```
##  median     mean        sd   n
##  0.6445 0.646176 0.1475161 250
```



```r
favstats(danceability ~ playlist_genre, data = spotify_songs) %&gt;%
  select(playlist_genre, median, mean, sd, n)
```

```
##   playlist_genre median      mean        sd  n
## 1            edm 0.6210 0.6407105 0.1185723 38
## 2          latin 0.7175 0.7181750 0.1192336 40
## 3            pop 0.6275 0.6499773 0.1299672 44
## 4            r&amp;b 0.6795 0.6550000 0.1302288 48
## 5            rap 0.7875 0.7388824 0.1517192 34
## 6           rock 0.5240 0.5067174 0.1212052 46
```

- Rap and Latin music have the highest mean danceability, whereas rock has the lowest. 

- Similar levels of variability within each genre. 

---

# Dataviz


```r
gf_boxplot(danceability ~ playlist_genre, data = spotify_songs) + 
  labs(x = "", y = "Danceability") + 
  theme_minimal()
```

&lt;img src="08-One_Way_ANOVA_files/figure-html/unnamed-chunk-6-1.png" width="50%" /&gt;

---

# Dataviz


```r
gf_density( ~ danceability, fill = ~ playlist_genre, data = spotify_songs) + 
  labs(x = "Danceability", fill = "Genre") + 
  theme_minimal()
```

&lt;img src="08-One_Way_ANOVA_files/figure-html/unnamed-chunk-7-1.png" width="50%" /&gt;

---

# Research Question

Is there a difference in the **average** danceability among the six genres?

- To compare the means of *two groups*, we used a **permutation test** for the *difference between two means* (or the theory-based *t*-test, provided a few assumptions and conditions are met). 

--

- To compare the means of *more than two groups*, we will use a test called the **one-way analysis of variance (ANOVA)**.
    - The "one-way" refers to *one* explanatory variable (in this case, `playlist_genre`).

---

# ANOVA

The **ANOVA** is used to assess whether the mean of the outcome variable (*y*) is different for different levels of a categorical explanatory variable (*x*).

Let `\(\mu_{i}\)` be the mean of group `\(i\)`. 

- `\(H_{0}\)`: The mean outcome is **the same** across each category. `$$\mu_{1}=\mu_{2}=\cdots=\mu_{k}$$`

- `\(H_{a}\)`: *At least one* mean is **different** from the others. 

--

*Conditions*

1. The observations should be **independent** *within* and *between* groups. 
    
2. The observations *within* each group should be **approximately normal**. 

    - Check histograms or boxplots for symmetric/unimodal distributions. 
    
3. The **variability** *across each group* should be about equal. 

    - Especially if the sample sizes differ between groups. 

---

# The ANOVA Table

To perform a one-way ANOVA (also called the **F-test**), we will construct a one way ANOVA table and *reverse engineer* it. 


```r
anova_table = aov(danceability ~ playlist_genre, data = spotify_songs)
summary(anova_table)
```

```
                Df Sum Sq Mean Sq F value   Pr(&gt;F)    
playlist_genre   5  1.400 0.27994      17 2.05e-14 ***
Residuals      244  4.019 0.01647                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

--

- "Sum Sq" is short for **Sum of Squares**, and "Mean Sq" is short for **Mean Square**. 

- The `playlist_genre` row gives information on the variability **between** genres. 
- The `Residuals` row gives information on the variability **within** genre. 

---

# Sum of Squares (Between)

The two **sum of squares** (1.4 and 4.019) are based on the values in this table below. 

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Genre &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Mean.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SD.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; n &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; EDM &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Latin &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.72 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Pop &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; R&amp;amp;B &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.66 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rap &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.74 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rock &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.51 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; TOTAL &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 250 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

The sum of squares *between* genres (1.4) is a measure of the variability among the *k* = 6 genres and the overall mean danceability (0.65). 

--

`\begin{align*}
SS_{between}&amp;=38(0.65-0.65)^{2}+40(0.72-0.65)^{2}+44(0.65-0.65)^{2}+48(0.66-0.65)^{2}\\ 
&amp;\ \ \ \ +34(0.74-0.65)^{2} + 46(0.51-0.65)^{2}\\
&amp;\approx 1.4
\end{align*}`

---

# Sum of Squares (Within)

The two **sum of squares** (1.4 and 4.019) are based on the values in this table below. 

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Genre &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Mean.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SD.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; n &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; EDM &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Latin &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.72 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Pop &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; R&amp;amp;B &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.66 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rap &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.74 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rock &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.51 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; TOTAL &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 250 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

The sum of squares *within* genres (4.019) is a composite measure of the variability in the values within each genre. 

--

`\begin{align*}
SS_{within}&amp;=(38-1)s_{1}^{2}+(40-1)s_{2}^{2}+(44-1)s_{3}^{2}+(48-1)s_{4}^{2}+(34-1)s_{5}^{2}+(46-1)s_{6}^{2}\\
&amp;=37(0.12)^{2}+39(0.12)^{2}+43(0.13)^{2}+47(0.13)^{2}+33(0.15)^{2}+45(0.12)^{2}\\
&amp;\approx 4.019
\end{align*}`

---

# Sum of Squares

In general when comparing *k* groups, `$$SS_{between}=\sum_{i=1}^{k}n_{i}(\bar{y}_{i}-\bar{y})^{2}$$`
and 
`\begin{align*}
SS_{within}&amp;=\sum_{i=1}^{k}(n_{i}-1)s_{i}^{2}\\
&amp;=\sum_{i=1}^{k}\sum_{j=1}^{n_{i}}(y_{ij}-\bar{y})^{2}
\end{align*}`
using the formula for `\(s_{i}^{2}\)`. 

---

# Unpacking Sum of Squares

If all of the group means were **identical**: `$$\bar{y}_{1}=\bar{y}_{2}=\bar{y}_{3}=\bar{y}_{4}=\bar{y}_{5}=\bar{y}_{6}=\bar{y}$$`
then `\(SS_{between}=0\)`, implying there is *zero observed variability between group means*.

If observations within each group were **identical**: `$$y_{11}=y_{12}=\cdots=y_{1n_{1}},\qquad y_{21}=y_{22}=\cdots=y_{2n_{2}},\qquad \text{etc.}$$`
then `\(SS_{within}=0\)`, implying there is *zero observed variability within groups*. 

--

As the group means get *farther apart*, the deviations `\((\bar{y}_{i}-\bar{y})\)` increase in absolute value. 

- This gives us greater evidence favoring **rejecting the null hypothesis**. 

---

# Unpacking Sum of Squares (Navarro, Ch. 14)

**Between Groups** variation

.center[
&lt;img src="var_between.png" width="351" /&gt;
]

**Within Groups** variation

.center[
&lt;img src="var_within.png" width="362" /&gt;
]

---

# Unpacking Sum of Squares

We have found out that the *total variability* associated with the response variable (danceability, in this example) can be broken down into:

- Sum of the variation due to differences in sample means *between groups*

- Sum of the variation due to differences among observations *within groups*

How does this tell us if the **average** danceability is different between genres?!

--

If the **null hypothesis** were true, we would expect all of the sample means to be pretty similar (i.e., a small `\(SS_{between}\)` relative to `\(SS_{within}\)`).

- So if `\(SS_{between}\)` is *large* relative to `\(SS_{within}\)`, we would have reason to suspect that the population means for different groups are not *all identical* to each other. 

---

# Degrees of Freedom


```
                Df Sum Sq Mean Sq F value   Pr(&gt;F)    
playlist_genre   5  1.400 0.27994      17 2.05e-14 ***
Residuals      244  4.019 0.01647                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Associated with each sum of squares is a number of **degrees of freedom** (*df*). 

- For `\(SS_{between}\)` (the `playlist_genre` row), `\(df=\text{number of groups}-1=5\)`. 

- For `\(SS_{within}\)` (the `Residuals` row), `\(df=n-\text{number of groups}=250-6=244\)`.

--

Dividing each of `\(SS_{between}\)` and `\(SS_{within}\)` by their corresponding *df* gives a **mean square**:

- `\(MS_{between}=1.4/5=0.28\)`

- `\(MS_{within}=4.019/244=0.016\)`

---

# Test Statistic

The **test statistic** for a one-way ANOVA is `$$F=\frac{MS_{between}}{MS_{within}}=\frac{0.28}{0.016}=17$$`

Under the null hypothesis, the test statistic is said to come from an **F-distribution**, in which the shape depends on the two `\(df\)` values. 

Here is the F-distribution for `\(df_{1}=5\)` and `\(df_{2}=244\)`:
.center[
&lt;img src="08-One_Way_ANOVA_files/figure-html/unnamed-chunk-14-1.png" width="35%" /&gt;
]

---

# Test Statistic

`$$F=\frac{MS_{between}}{MS_{within}}=\frac{0.28}{0.016}=17$$`

- Think of `\(MS_{between}\)` as a measure of variability *between groups*, and `\(MS_{within}\)` as a measure of variability *within groups*. 

- Under the null hypothesis, the variability between and within groups should be about equal. 

---

# p-value


```
                Df Sum Sq Mean Sq F value   Pr(&gt;F)    
playlist_genre   5  1.400 0.27994      17 2.05e-14 ***
Residuals      244  4.019 0.01647                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

The p-value is given in the ANOVA table, and is evident both by the large value of `\(F\)` and its place in the graph of the *null distribution* on the previous slide. 

We can **reject the null hypothesis** and conclude that *at least one* of the six examined genres has an average danceability that is significantly different from the others. 

---

# Checking the Equal Variance Condition

Condition #3 on a previous slide stated that the variability *across each group* should be about equal. 

--

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Genre &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Mean.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SD.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; n &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; EDM &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Latin &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.72 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Pop &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; R&amp;amp;B &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.66 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rap &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.74 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rock &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.51 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; TOTAL &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 250 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

Let `\(S_{max}\)` be the largest standard deviation and `\(S_{min}\)` be the smallest. Then the equal variability condition is valid if: `$$\frac{S_{max}}{S_{min}}&lt;2$$`

---

# Checking the Equal Variance Condition

.center[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Genre &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Mean.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SD.dance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; n &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; EDM &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 38 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Latin &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.72 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Pop &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; R&amp;amp;B &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.66 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rap &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.74 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Rock &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.51 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 46 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; TOTAL &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.65 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 250 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

- In this example, `\(S_{max}/S_{min}=0.15/0.12=1.25\)`, so this should be okay... 

--

But what if it wasn't?!

.center[
&lt;img src="blush_emoji.png" width="15%" /&gt;
]

---

class: center, middle, frame

# Permutation F-Tests

---

# Reminder: `infer`

`infer` to the rescue!

&lt;img src="infer_hex.png" width="15%" /&gt;

.center[
&lt;img src="infer_pipeline.png" width="85%" /&gt;

]

---

# One Permutation

Let's take one permutation from the `spotify_songs` data:




```r
one_perm = spotify_songs %&gt;%
  specify(response = danceability, explanatory = playlist_genre) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1, type = "permute")
View(one_perm)
```



---

# What's going on here?

.pull-left[

```
Response: danceability (numeric)
Explanatory: playlist_genre (factor)
Null Hypothesis: independence
# A tibble: 250 x 3
# Groups:   replicate [1]
   danceability playlist_genre replicate
          &lt;dbl&gt; &lt;fct&gt;              &lt;int&gt;
 1        0.794 pop                    1
 2        0.636 r&amp;b                    1
 3        0.707 latin                  1
 4        0.468 latin                  1
 5        0.854 pop                    1
 6        0.768 rap                    1
 7        0.612 rap                    1
 8        0.67  rap                    1
 9        0.701 rap                    1
10        0.554 edm                    1
# â€¦ with 240 more rows
```
]

.pull-right[
If the average danceability for each genre was equal (i.e., if danceability and genre were **independent**)...

- ...then we might as well *shuffle* the different songs and their danceabilities between genres. 

]

---

# One Permutation

Now let's calculate the *F* statistic for the *single permutation*:


```r
one_perm %&gt;%
  calculate(stat = "F")
```

```
Response: danceability (numeric)
Explanatory: playlist_genre (factor)
Null Hypothesis: independence
# A tibble: 1 x 1
   stat
  &lt;dbl&gt;
1  1.28
```

Chances are, your *F* statistic was small. 

- Remember, `one_perm` comes from a world where genre and danceability are *independent*. So the *F* statistic should be small!

---

# Many Permutations

As before, let's generate 1,000 (or more) permutations!




```r
null_distribution_F = spotify_songs %&gt;%
  specify(response = danceability, explanatory = playlist_genre) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "F")
```

---

# Visualize the Null Distribution


```r
visualize(null_distribution_F, method = "both")
```

&lt;img src="08-One_Way_ANOVA_files/figure-html/unnamed-chunk-28-1.png" width="50%" /&gt;

---

# Visualize the Null Distribution


```r
visualize(null_distribution_F) + 
* shade_p_value(obs_stat = 17, direction = "greater")
```

&lt;img src="08-One_Way_ANOVA_files/figure-html/unnamed-chunk-29-1.png" width="50%" /&gt;

---

# P-value

Let's use `get_p_value()`:


```r
null_distribution_F %&gt;%
  get_p_value(obs_stat = 17, direction = "greater")
```

```
# A tibble: 1 x 1
  p_value
    &lt;dbl&gt;
1       0
```


Compare this with the P-value obtained using the **theoretical test**:


```
                Df Sum Sq Mean Sq F value   Pr(&gt;F)    
playlist_genre   5  1.400 0.27994      17 2.05e-14 ***
Residuals      244  4.019 0.01647                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

# Conclusion

Using a permutation F-test, *we reject the null hypothesis* that the average danceability for each genre are equal. 

- We have sufficient evidence to conclude that at least one mean is different. 

You might be asking yourselves something...

**Which mean is different?!**

---

class: center, middle, frame

# Multiple Comparisons and Post-Hoc Tests

---

# Post-ANOVA Analyses

If you run an ANOVA with more than two groups and *reject the null hypothesis* (i.e., a significant effect), all this tells you is that **at least one group mean is different from the rest**. 

- A natural follow-up question to ask is: **Which groups are different from one another?**

--

Recall the null hypothesis from the `gapminder` example: `$$H_{0}:\mu_{edm}=\mu_{latin}=\mu_{pop}=\mu_{r\&amp;b}=\mu_{rap}=\mu_{rock}$$`

In this null hypothesis, we are actually claiming **15** *different things simultaneously*:
- The average danceability of EDM and Latin songs are equal. 
- The average danceability of EDM and Pop are equal. 
- ...and so on!

---

# Post-ANOVA Analyses

If any of those 15 claims are false, then we **reject the null**. But which claim(s) are false?

Given that we have 15 different **pairs of means** to compare, we could just run separate "post-hoc" hypothesis tests for two means!

- Either 15 **two-sample t-tests**, or 15 **permutation tests**

---

# Running "Pairwise" Tests

Let's compare the average danceability of EDM and Pop, `\(\mu_{edm}\)` and `\(\mu_{pop}\)`. 

To do this, we have to take the `spotify_songs` data and `filter()` those two genres:


```r
spotify_edm_pop = spotify_songs %&gt;%
  filter(playlist_genre %in% c("edm", "pop"))
```

Next, run a two-sample *t*-test:


```r
t.test(danceability ~ playlist_genre, data = spotify_edm_pop)
```

---

# Running "Pairwise" Tests

Or, run a *permutation test*:


```r
# Sample statistic
xbar_diff = spotify_edm_pop %&gt;%
  specify(response = danceability, explanatory = playlist_genre) %&gt;%
  calculate(stat = "diff in means", order = c("edm", "pop"))
```


```r
# Hypothesis test
spotify_edm_pop %&gt;%
  specify(response = danceability, explanatory = playlist_genre) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 1000, type = "permute") %&gt;%
  calculate(stat = "diff in means", order = c("edm", "pop")) %&gt;%
  get_p_value(obs_stat = xbar_diff, direction = "both")
```

```
# A tibble: 1 x 1
  p_value
    &lt;dbl&gt;
1   0.736
```

---

# Problems with Many Pairwise Tests

It wouldn't take *too much* time to run all 15 pairwise comparisons to find *which group means* are different. 

However, there are some *problems* with this:

- It is **incredibly tedious**. 

    - Imagine if we had **ten** means to compare instead of **six**. That would mean `\(\binom{10}{2}=45\)` pairwise comparisons!
    
--

- This is **p-hacking**, or fishing through many pairwise comparisons until we find the significant ones. 

    - p-hacking, like *pie charts*, is **bad**!


- We set `\(\alpha\)`, or the *significance level* to be 0.05 in each test!

    - Remember, `\(alpha\)` is also the probability of **Type I Error** (falsely rejecting a null hypothesis). 

---

# p-hacking

.center[
&lt;img src="p_hacking.png" width="528" /&gt;
]

---

# Study Design

15 subjects (!) recruited to take part in a study on "dieting"
- Aged 19-67 years

- Randomly assigned to one of three diet groups:
    - low carb group
    - low carb plus 1.5 oz chocolate group
    - control group (no changes made to diet)
    
- Weighed each morning for 21 days
    
--

**Results**

The *low carb plus 1.5 oz chocolate* group lost weight 10% faster than the low carb group!!!

- This group also had statistically significantly better cholesterol and well-being measures. 

---

# What REALLY happened?

The researchers measured **18 different things**: weight, cholesterol, sodium, blood protein levels, sleep, well-being, etc.

- If you measure many things on a small number of people, you have a very high chance of obtaining a *significant result*!

Think of each measurement as a "lottery ticket," where "winning" is attaining *statistical significance*. 

For 18 separate "tests", 
`\begin{align*}
P(\text{winning})&amp;=1-P(\text{losing on all 18 tests})\\
&amp;=1-(1-0.05)^{18}=0.6027857
\end{align*}`

There is a **60% chance** of having a *statistically significant result* (p-value &lt; 0.05) just by chance!

---

# Post-Hoc Tests

Let's focus a bit more on the *third problem* of conducting many pairwise tests:
- We set `\(\alpha\)`, or the *significance level* to be 0.05 in each test!

We had 15 pairwise comparisons. 
- But if we had 45 comparisons, we could *expect* at least to *incorrectly reject a null hypothesis* in at least two or three tests just by chance alone!
  

**A solution?**

Use a **correction for multiple comparisons**, which is an adjustment to the p-value for each post-hoc test. 

There are many methods to correct for multiple comparisons, but we will use **Tukey's HSD (Honestly Significant Difference) test**. 

- Another is the **Bonferroni correction**, which simply multiplies each *pairwise P-value* by the number of total comparisons.

---

# Tukey's HSD


```r
anova_table = aov(danceability ~ playlist_genre, data = spotify_songs)
TukeyHSD(anova_table)
```

```
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = danceability ~ playlist_genre, data = spotify_songs)

$playlist_genre
                   diff          lwr         upr     p adj
latin-edm   0.077464474 -0.006045606  0.16097455 0.0862751
pop-edm     0.009266746 -0.072373100  0.09090659 0.9995066
r&amp;b-edm     0.014289474 -0.065758473  0.09433742 0.9956511
rap-edm     0.098171827  0.011145955  0.18519770 0.0169197
rock-edm   -0.133993135 -0.214806337 -0.05317993 0.0000479
pop-latin  -0.068197727 -0.148734959  0.01233950 0.1492696
r&amp;b-latin  -0.063175000 -0.142098095  0.01574810 0.1982957
rap-latin   0.020707353 -0.065284992  0.10669970 0.9827498
rock-latin -0.211457609 -0.291156761 -0.13175846 0.0000000
r&amp;b-pop     0.005022727 -0.071918719  0.08196417 0.9999677
rap-pop     0.088905080  0.004727799  0.17308236 0.0316570
rock-pop   -0.143259881 -0.220997170 -0.06552259 0.0000040
rap-r&amp;b     0.083882353  0.001248075  0.16651663 0.0443433
rock-r&amp;b   -0.148282609 -0.224346367 -0.07221885 0.0000009
rock-rap   -0.232164962 -0.315540760 -0.14878916 0.0000000
```


---

# Tukey's HSD (Details)

When using a correction for multiple comparisons, the 5% level of significance and the confidence level (95%) apply to the **family consisting of all pairwise comparisons**. 

In this example, the **family level of significance**, `\(\alpha=0.05\)`, is defined as: `$$P(\text{at least one Type I Error in the 15 tests})=0.05$$`


**Note**: Tukey's HSD, and all **post-hoc tests**, should be performed *after* a significant F-test.

---

# Practice

**Question**: Is there an association between the `carrier` and *departure delay* (`dep_delay`) in flights leaving from NYC? Let's use an ANOVA to find out!


```r
library(nycflights13)

set.seed(227)
flights_sample = flights %&gt;%
  filter(carrier %in% c("9E", "AA", "B6", "DL", "EV", 
                        "FL", "MQ", "UA", "US", "VX", "WN")) %&gt;%
  slice_sample(n = 2000)
```

1. Perform EDA (i.e., construct a **table of descriptive stats** and *appropriate visualizations*).

2. Perform the **one-way ANOVA**. 
    - State the test statistic, p-value, and conclusion. 
    
3. Perform **post-hoc tests** (if necessary). 

ðŸš¨Were the conditions met?ðŸš¨



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false,
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
